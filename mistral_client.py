import json
import logging
from mistralai import Mistral
from typing import Dict, Any, List

from base import BaseLLMClient
from config import config
from prompts import prompts

logger = logging.getLogger(__name__)

class MistralClient(BaseLLMClient):
    """–†–µ–∞–ª–∏–∑–∞—Ü–∏—è –¥–ª—è Mistral AI"""
    
    def __init__(self):
        self.client = Mistral(api_key=config.MISTRAL_API_KEY)
        self.model = config.LLM_MODEL
    
    def chat_completion(self, messages: List[Dict[str, str]], **kwargs) -> str:
        """–ü–æ–ª—É—á–µ–Ω–∏–µ –æ—Ç–≤–µ—Ç–∞ –æ—Ç Mistral"""
        try:
            response = self.client.chat.complete(
                model=self.model,
                messages=messages,
                **kwargs
            )
            return response.choices[0].message.content
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ Mistral API: {e}")
            raise
    
    def analyze_preferences(self, text: str, categories: List[str]) -> Dict[str, Any]:
        """–ê–Ω–∞–ª–∏–∑ –ø—Ä–µ–¥–ø–æ—á—Ç–µ–Ω–∏–π –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è"""
        prompt = prompts.PREFERENCE_ANALYZER.format(
            user_input=text,
            categories=', '.join(categories)
        )
        
        try:
            response = self.client.chat.complete(
                model=self.model,
                messages=[
                    {"role": "system", "content": "–¢—ã –≤—Å–µ–≥–¥–∞ –≤–æ–∑–≤—Ä–∞—â–∞–µ—à—å —Ç–æ–ª—å–∫–æ –≤–∞–ª–∏–¥–Ω—ã–π JSON."},
                    {"role": "user", "content": prompt}
                ],
                temperature=0.1
            )
            
            response_text = response.choices[0].message.content.strip()
            
            if response_text.startswith('```'):
                lines = response_text.split('\n')
                response_text = '\n'.join(lines[1:-1]) if len(lines) > 2 else lines[0]
            
            result = json.loads(response_text)
            
            if "categories" not in result:
                result["categories"] = []
            if "explanation" not in result:
                result["explanation"] = "–û–ø—Ä–µ–¥–µ–ª–µ–Ω–æ –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏"
            
            return result
            
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –∞–Ω–∞–ª–∏–∑–∞ –ø—Ä–µ–¥–ø–æ—á—Ç–µ–Ω–∏–π: {e}")
            return self._fallback_category_detection(text, categories)
    
    def generate_recommendations(self, parsed_data: List[Dict[str, Any]], categories: List[str]) -> str:
        """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–π –Ω–∞ –æ—Å–Ω–æ–≤–µ —Ä–∞—Å–ø–∞—Ä—Å–µ–Ω–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö"""
        if not parsed_data:
            return "–ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é —Å —Å–∞–π—Ç–æ–≤."
        
        # –§–æ—Ä–º–∏—Ä—É–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ —Å–∞–π—Ç–∞—Ö
        sites_info = []
        for data in parsed_data:
            site_info = f"\n–°–∞–π—Ç: {data['url']}\n"
            site_info += f"–ù–∞–∑–≤–∞–Ω–∏–µ: {data['title']}\n"
            if data.get('content'):
                site_info += f"–ö–æ–Ω—Ç–µ–Ω—Ç: {data['content'][:500]}...\n"
            sites_info.append(site_info)
        
        prompt = prompts.RECOMMENDATION_GENERATOR.format(
            categories=', '.join(categories),
            sites_info='\n---\n'.join(sites_info)
        )
        
        try:
            return self.chat_completion(
                messages=[
                    {"role": "system", "content": "–¢—ã –¥–∞–µ—à—å —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –ø–æ –º–µ—Å—Ç–∞–º –æ—Ç–¥—ã—Ö–∞."},
                    {"role": "user", "content": prompt}
                ],
                temperature=0.7,
                max_tokens=1500
            )
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–π: {e}")
            return "–ù–µ —É–¥–∞–ª–æ—Å—å —Å—Ñ–æ—Ä–º–∏—Ä–æ–≤–∞—Ç—å —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏."
    
    def _fallback_category_detection(self, text: str, available_categories: List[str]) -> Dict[str, Any]:
        """–†–µ–∑–µ—Ä–≤–Ω—ã–π –º–µ—Ç–æ–¥ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è –∫–∞—Ç–µ–≥–æ—Ä–∏–π"""
        text_lower = text.lower()
        categories = []
        
        keyword_mapping = {
            "üèõÔ∏è –ú—É–∑–µ–∏": ['–º—É–∑–µ–π', '–∏—Å—Ç–æ—Ä–∏', '—ç–∫—Å–ø–æ–∑'],
            "üé® –ò—Å–∫—É—Å—Å—Ç–≤–æ/–í—ã—Å—Ç–∞–≤–∫–∏": ['–∏—Å–∫—É—Å—Å—Ç–≤', '–≤—ã—Å—Ç–∞–≤–∫', '–≥–∞–ª–µ—Ä–µ', '–∞—Ä—Ç'],
            "üçΩÔ∏è –†–µ—Å—Ç–æ—Ä–∞–Ω—ã/–ö–∞—Ñ–µ": ['—Ä–µ—Å—Ç–æ—Ä–∞–Ω', '–∫–∞—Ñ–µ', '–µ–¥–∞', '–∫—É—Ö–Ω'],
            "‚òï –ö–æ—Ñ–µ–π–Ω–∏": ['–∫–æ—Ñ–µ', '–∫–æ—Ñ–µ–π–Ω'],
            "üèûÔ∏è –ü–∞—Ä–∫–∏/–ü—Ä–æ–≥—É–ª–∫–∏": ['–ø–∞—Ä–∫', '–ø—Ä–æ–≥—É–ª', '—Å–∫–≤–µ—Ä'],
            "üé≠ –¢–µ–∞—Ç—Ä—ã/–ö–æ–Ω—Ü–µ—Ä—Ç—ã": ['—Ç–µ–∞—Ç—Ä', '–∫–æ–Ω—Ü–µ—Ä—Ç', '—Å–ø–µ–∫—Ç–∞–∫–ª'],
            "üé≥ –†–∞–∑–≤–ª–µ—á–µ–Ω–∏—è": ['–∫–∏–Ω–æ', '–±–æ—É–ª–∏–Ω–≥', '–∫–≤–µ—Å—Ç'],
            "üõçÔ∏è –®–æ–ø–ø–∏–Ω–≥": ['–º–∞–≥–∞–∑–∏–Ω', '—à–æ–ø–ø–∏–Ω–≥', '—Ç–æ—Ä–≥–æ–≤'],
            "üé™ –°–æ–±—ã—Ç–∏—è/–§–µ—Å—Ç–∏–≤–∞–ª–∏": ['—Ñ–µ—Å—Ç–∏–≤–∞–ª', '—Å–æ–±—ã—Ç–∏', '–º–µ—Ä–æ–ø—Ä–∏—è—Ç'],
            "üçª –ë–∞—Ä—ã/–ü–∞–±—ã": ['–±–∞—Ä', '–ø–∞–±', '–ø–∏–≤–æ', '–∫–æ–∫—Ç–µ–π–ª']
        }
        
        for category, keywords in keyword_mapping.items():
            if category in available_categories and any(k in text_lower for k in keywords):
                categories.append(category)
        
        if not categories:
            categories = available_categories[:2] if available_categories else []
        
        return {
            "categories": categories[:3],
            "explanation": f"–û–ø—Ä–µ–¥–µ–ª–µ–Ω–æ –ø–æ –∫–ª—é—á–µ–≤—ã–º —Å–ª–æ–≤–∞–º: {', '.join(categories)}"
        }